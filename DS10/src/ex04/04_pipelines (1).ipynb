{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 04\n",
    "# Pipelines and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three custom transformers, the first two out of which will be used within a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "1. `FeatureExtractor()` class:\n",
    " - Takes a dataframe with `uid`, `labname`, `numTrials`, `timestamp` from the file [`checker_submits.csv`](https://drive.google.com/file/d/14voc4fNJZiLEFaZyd8nEG-lQt5JjatYw/view?usp=sharing).\n",
    " - Extracts `hour` from `timestamp`.\n",
    " - Extracts `weekday` from `timestamp` (numbers).\n",
    " - Drops the `timestamp` column.\n",
    " - Returns the new dataframe.\n",
    "\n",
    "\n",
    "2. `MyOneHotEncoder()` class:\n",
    " - Takes the dataframe from the result of the previous transformation and the name of the target column.\n",
    " - Identifies all the categorical features and transforms them with `OneHotEncoder()`. If the target column is categorical too, then the transformation should not apply to it.\n",
    " - Drops the initial categorical features.\n",
    " - Returns the dataframe with the features and the series with the target column.\n",
    "\n",
    "\n",
    "3. `TrainValidationTest()` class:\n",
    " - Takes `X` and `y`.\n",
    " - Returns `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` (`test_size=0.2`, `random_state=21`, `stratified`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>labname</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>user_19</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid   labname  numTrials  hour  weekday\n",
       "0      user_4  project1          1     5        4\n",
       "1      user_4  project1          2     5        4\n",
       "2      user_4  project1          3     5        4\n",
       "3      user_4  project1          4     5        4\n",
       "4      user_4  project1          5     5        4\n",
       "...       ...       ...        ...   ...      ...\n",
       "1681  user_19   laba06s          9    20        3\n",
       "1682   user_1   laba06s          6    20        3\n",
       "1683   user_1   laba06s          7    20        3\n",
       "1684   user_1   laba06s          8    20        3\n",
       "1685   user_1   laba06s          9    20        3\n",
       "\n",
       "[1686 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureExtractor(object):\n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        self.df = df\n",
    "    def extract(self):\n",
    "        self.df['hour'] = self.df['timestamp'].dt.hour\n",
    "        self.df['weekday'] = self.df['timestamp'].dt.weekday\n",
    "        self.df.drop(columns=['timestamp'], inplace=True)\n",
    "        return self.df\n",
    "\n",
    "df = FeatureExtractor(pd.read_csv('../data/checker_submits.csv',parse_dates=['timestamp']))\n",
    "df = df.extract()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>labname</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>user_19</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid   labname  numTrials  hour  weekday\n",
       "0      user_4  project1          1     5        4\n",
       "1      user_4  project1          2     5        4\n",
       "2      user_4  project1          3     5        4\n",
       "3      user_4  project1          4     5        4\n",
       "4      user_4  project1          5     5        4\n",
       "...       ...       ...        ...   ...      ...\n",
       "1681  user_19   laba06s          9    20        3\n",
       "1682   user_1   laba06s          6    20        3\n",
       "1683   user_1   laba06s          7    20        3\n",
       "1684   user_1   laba06s          8    20        3\n",
       "1685   user_1   laba06s          9    20        3\n",
       "\n",
       "[1686 rows x 5 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uid'] = df['uid'].astype('category')\n",
    "df['labname'] = df['labname'].astype('category')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials  hour  weekday  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0             1     5        4         0.0         0.0          0.0   \n",
       "1             2     5        4         0.0         0.0          0.0   \n",
       "2             3     5        4         0.0         0.0          0.0   \n",
       "3             4     5        4         0.0         0.0          0.0   \n",
       "4             5     5        4         0.0         0.0          0.0   \n",
       "...         ...   ...      ...         ...         ...          ...   \n",
       "1681          9    20        3         0.0         0.0          0.0   \n",
       "1682          6    20        3         0.0         1.0          0.0   \n",
       "1683          7    20        3         0.0         1.0          0.0   \n",
       "1684          8    20        3         0.0         1.0          0.0   \n",
       "1685          9    20        3         0.0         1.0          0.0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1682          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1683          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1684          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1685          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0               0.0             0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0             0.0   \n",
       "3               0.0             0.0             0.0             0.0   \n",
       "4               0.0             0.0             0.0             0.0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681            0.0             0.0             0.0             0.0   \n",
       "1682            0.0             0.0             0.0             0.0   \n",
       "1683            0.0             0.0             0.0             0.0   \n",
       "1684            0.0             0.0             0.0             0.0   \n",
       "1685            0.0             0.0             0.0             0.0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                 0.0             0.0             0.0              0.0   \n",
       "1                 0.0             0.0             0.0              0.0   \n",
       "2                 0.0             0.0             0.0              0.0   \n",
       "3                 0.0             0.0             0.0              0.0   \n",
       "4                 0.0             0.0             0.0              0.0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681              0.0             0.0             0.0              1.0   \n",
       "1682              0.0             0.0             0.0              1.0   \n",
       "1683              0.0             0.0             0.0              1.0   \n",
       "1684              0.0             0.0             0.0              1.0   \n",
       "1685              0.0             0.0             0.0              1.0   \n",
       "\n",
       "      labname_project1  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "1681               0.0  \n",
       "1682               0.0  \n",
       "1683               0.0  \n",
       "1684               0.0  \n",
       "1685               0.0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyOneHotEncoder(object):\n",
    "    def __init__(self,df:pd.DataFrame,target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "    def tranfrom(self):\n",
    "        cat_col = [col for col in self.df.columns if self.df[col].dtype == 'category' and col != self.target]\n",
    "        enc = OneHotEncoder(sparse_output=False)\n",
    "        data = enc.fit_transform(self.df[cat_col])\n",
    "        temp_df = pd.DataFrame(data, columns=enc.get_feature_names_out())\n",
    "        self.df=pd.concat([self.df, temp_df], axis=1).drop(columns=['uid', 'labname'])\n",
    "        return self.df\n",
    "df = MyOneHotEncoder(df,'weekday').tranfrom()\n",
    "df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['weekday'])\n",
    "y=df['weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValidationTest():\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def train(self):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(self.X,self.Y,test_size=0.2,random_state=21,stratify=self.Y)\n",
    "        X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size=0.2,random_state=21,stratify=y_train)\n",
    "        return X_train,X_test,y_train,y_test,X_valid,y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,X_valid,y_valid = TrainValidationTest(X,y).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSelection()` class\n",
    "\n",
    " - Takes a list of `GridSearchCV` instances and a dict where the keys are the indexes from that list and the values are the names of the models, the example is below in the reverse order (from high-level to low-level perspective):\n",
    "\n",
    "```\n",
    "ModelSelection(grids, grid_dict)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs), where jobs you can specify by yourself\n",
    "\n",
    "svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None), 'random_state':[21], 'probability':[True]}]\n",
    "```\n",
    "\n",
    " - Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` and returns the name of the best classifier among all the models on the validation set\n",
    " - Method `best_results()` returns a dataframe with the columns `model`, `params`, `valid_score` where the rows are the best models within each class of models.\n",
    "\n",
    "```\n",
    "model\tparams\tvalid_score\n",
    "0\tSVM\t{'C': 10, 'class_weight': None, 'gamma': 'auto...\t0.877778\n",
    "1\tDecision Tree\t{'class_weight': 'balanced', 'criterion': 'gin...\t0.866667\n",
    "2\tRandom Forest\t{'class_weight': None, 'criterion': 'entropy',...\t0.907407\n",
    "```\n",
    "\n",
    " - When you iterate through the parameters of a model class, print the name of that class and show the progress using `tqdm.notebook`, in the end of the cycle print the best model of that class.\n",
    "\n",
    "```\n",
    "Estimator: SVM\n",
    "100%\n",
    "125/125 [01:32<00:00, 1.36it/s]\n",
    "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
    "Best training accuracy: 0.773\n",
    "Validation set accuracy score for best params: 0.878 \n",
    "\n",
    "Estimator: Decision Tree\n",
    "100%\n",
    "57/57 [01:07<00:00, 1.22it/s]\n",
    "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
    "Best training accuracy: 0.801\n",
    "Validation set accuracy score for best params: 0.867 \n",
    "\n",
    "Estimator: Random Forest\n",
    "100%\n",
    "284/284 [06:47<00:00, 1.13s/it]\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50, 'random_state': 21}\n",
    "Best training accuracy: 0.855\n",
    "Validation set accuracy score for best params: 0.907 \n",
    "\n",
    "Classifier with best validation set accuracy: Random Forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(probability=True,random_state=21)\n",
    "param_grid_svm = [{\n",
    "    'kernel' : ('linear','rbf','sigmoid'),\n",
    "    'C' : [0.01,0.1,1,1.5,5,10],\n",
    "    'gamma' : ['scale','auto'],\n",
    "    'class_weight' : ('balanced','None'),\n",
    "    'random_state':[21], \n",
    "    'probability':[True]\n",
    "}]\n",
    "grid_svm = GridSearchCV(model_svm,param_grid=param_grid_svm,cv=2,scoring='accuracy',n_jobs=-1,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_tree = [{\n",
    "    'max_depth' : range(1,50,5),\n",
    "    'criterion' : ['entropy','gini'],\n",
    "    'class_weight' : ['balanced','None']\n",
    "}]\n",
    "model_tree = DecisionTreeClassifier(random_state=21)\n",
    "grid_tree = GridSearchCV(model_tree,param_grid=param_grid_tree,n_jobs=-1,verbose=1,cv=2,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_random = {\n",
    "    'n_estimators' : [5,10,50,100],\n",
    "    'max_depth' : range(1,50),\n",
    "    'class_weight' : ['balanced','None'],\n",
    "    'criterion' : ['entropy','gini']\n",
    "}\n",
    "model_random = RandomForestClassifier(random_state=21)\n",
    "grid_random = GridSearchCV(model_random,param_grid_random,scoring='accuracy',n_jobs=-1,verbose=1,cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [grid_svm,grid_tree,grid_random]\n",
    "grid_dict = {0 : 'SVC', 1: 'DecisionTreeClassifier', 2 : 'RandomForestClassifier'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection(object):\n",
    "    def __init__(self,grids:list,grid_dict:dict):\n",
    "        self.grids = grids\n",
    "        self.grid_dict = grid_dict\n",
    "    def choose(self, X_train, y_train, X_valid, y_valid):\n",
    "        best_model_name = None\n",
    "        best_score = 0\n",
    "        for i, grid in enumerate(self.grids):\n",
    "            model_name = self.grid_dict[i]\n",
    "            print(f\"Estimator {model_name}\")\n",
    "\n",
    "            total_fits = len(grid.param_grid) * 2\n",
    "\n",
    "            with tqdm(total=total_fits, desc=f\"{model_name}\", ncols=100, unit=\"it/s\") as pbar:\n",
    "                grid.fit(X_train, y_train)\n",
    "\n",
    "                valid_score = grid.score(X_valid, y_valid)\n",
    "                if valid_score > best_score:\n",
    "                    best_score = valid_score\n",
    "                    best_model_name = model_name\n",
    "\n",
    "                pbar.update(total_fits)\n",
    "                print(f\"Best params: {grid.best_params_}\")\n",
    "                print(f\"Best training accuracy: {grid.best_score_:.3f}\")\n",
    "                print(f\"Validation set accuracy score for best params: {valid_score:.3f}\")\n",
    "\n",
    "        print(f\"\\nClassifier with best validation set accuracy: {best_model_name}\")\n",
    "        return best_model_name\n",
    "    def best_results(self, X_train, y_train, X_valid, y_valid):\n",
    "        models = []\n",
    "        params =  []\n",
    "        scores = []\n",
    "        for i, grid in enumerate(self.grids):\n",
    "            model_name = self.grid_dict[i]\n",
    "            models.append(model_name)\n",
    "            grid.fit(X_train, y_train)\n",
    "            params.append(grid.best_params_)\n",
    "            scores.append(grid.score(X_valid, y_valid))\n",
    "        return pd.DataFrame({'model': models, 'param' : params, 'valid_score': scores})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVC:   0%|                                                                  | 0/2 [00:00<?, ?it/s/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "72 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of SVC must be a str among {'balanced'}, an instance of 'dict' or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.27643785 0.12430427 0.12430427 0.27643785 0.12430427 0.12430427\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.47402597 0.16141002 0.14935065 0.47402597 0.29220779 0.06122449\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59090909 0.20037106 0.16512059 0.59090909 0.42207792 0.06215213\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60760668 0.2096475  0.17532468 0.60760668 0.46474954 0.05565863\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66883117 0.25510204 0.1419295  0.66883117 0.66233766 0.11595547\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67625232 0.28849722 0.12523191 0.67625232 0.75881262 0.09647495\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "SVC: 100%|██████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.63s/it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
      "Best training accuracy: 0.759\n",
      "Validation set accuracy score for best params: 0.859\n",
      "Estimator DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier:   0%|                                               | 0/2 [00:00<?, ?it/s/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.29962894 0.55565863 0.72820037 0.77458256 0.78571429 0.78571429\n",
      " 0.78571429 0.78571429 0.78571429 0.78571429 0.29962894 0.58534323\n",
      " 0.72541744 0.79499072 0.80705009 0.80705009 0.80705009 0.80705009\n",
      " 0.80705009 0.80705009        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "DecisionTreeClassifier: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 11.62it/s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n",
      "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21}\n",
      "Best training accuracy: 0.807\n",
      "Validation set accuracy score for best params: 0.867\n",
      "Estimator RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:   0%|                                               | 0/8 [00:00<?, ?it/s/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 784 candidates, totalling 1568 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "784 fits failed out of a total of 1568.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "393 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced_subsample', 'balanced'}, an instance of 'dict', an instance of 'list' or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "391 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced', 'balanced_subsample'}, an instance of 'dict', an instance of 'list' or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.29684601 0.40352505 0.46289425 0.45083488 0.35992579 0.40723562\n",
      " 0.51205937 0.49257885 0.4174397  0.49536178 0.5742115  0.56029685\n",
      " 0.51391466 0.55473098 0.62523191 0.61688312 0.50278293 0.60667904\n",
      " 0.68367347 0.68460111 0.62523191 0.67903525 0.72541744 0.73376623\n",
      " 0.67532468 0.73005566 0.74953618 0.76530612 0.68089054 0.74675325\n",
      " 0.79220779 0.78571429 0.73376623 0.76345083 0.81168831 0.81076067\n",
      " 0.72170686 0.7690167  0.81910946 0.81818182 0.75788497 0.78200371\n",
      " 0.81910946 0.82189239 0.75139147 0.79128015 0.82745826 0.82560297\n",
      " 0.783859   0.80890538 0.84044527 0.84137291 0.78849722 0.82374768\n",
      " 0.84137291 0.8432282  0.77272727 0.81168831 0.83766234 0.84044527\n",
      " 0.783859   0.80241187 0.8432282  0.84044527 0.77643785 0.80241187\n",
      " 0.84508349 0.84415584 0.79128015 0.82003711 0.84601113 0.8432282\n",
      " 0.77736549 0.81818182 0.84972171 0.84879406 0.78107607 0.8135436\n",
      " 0.84879406 0.84786642 0.78200371 0.81447124 0.84044527 0.84693878\n",
      " 0.78756957 0.80705009 0.84786642 0.84693878 0.783859   0.81818182\n",
      " 0.84230056 0.84693878 0.79220779 0.82003711 0.84693878 0.84786642\n",
      " 0.783859   0.81725417 0.8432282  0.84693878 0.78942486 0.81725417\n",
      " 0.84786642 0.84879406 0.78942486 0.81725417 0.84693878 0.85064935\n",
      " 0.78942486 0.81725417 0.84415584 0.84879406 0.78942486 0.81725417\n",
      " 0.84601113 0.85064935 0.78942486 0.81725417 0.84415584 0.85064935\n",
      " 0.78942486 0.81725417 0.84415584 0.85064935 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.30983302 0.40630798\n",
      " 0.45361781 0.46382189 0.3877551  0.41558442 0.52504638 0.52226345\n",
      " 0.43320965 0.49350649 0.57699443 0.56400742 0.50834879 0.57142857\n",
      " 0.61317254 0.60018553 0.54823748 0.61595547 0.66604824 0.65769944\n",
      " 0.60760668 0.65955473 0.72541744 0.73005566 0.64471243 0.69758813\n",
      " 0.7541744  0.76808905 0.6567718  0.71335807 0.78014842 0.7755102\n",
      " 0.68738404 0.73654917 0.79499072 0.80612245 0.71985158 0.77458256\n",
      " 0.80426716 0.81261596 0.73376623 0.78664193 0.81261596 0.82560297\n",
      " 0.75046382 0.80333952 0.83209647 0.83395176 0.76623377 0.80055659\n",
      " 0.83209647 0.83116883 0.77179963 0.80890538 0.83302412 0.83766234\n",
      " 0.76808905 0.80148423 0.83858998 0.84044527 0.78942486 0.82003711\n",
      " 0.84786642 0.84693878 0.79406308 0.81261596 0.85064935 0.84786642\n",
      " 0.79777365 0.8135436  0.85064935 0.84415584 0.78107607 0.79962894\n",
      " 0.84137291 0.84415584 0.7987013  0.81076067 0.84693878 0.84879406\n",
      " 0.79777365 0.81261596 0.8432282  0.84415584 0.80241187 0.82189239\n",
      " 0.85250464 0.85343228 0.81261596 0.82003711 0.85250464 0.85064935\n",
      " 0.82189239 0.81910946 0.84786642 0.84693878 0.80612245 0.82003711\n",
      " 0.84879406 0.84693878 0.80148423 0.81539889 0.84693878 0.84693878\n",
      " 0.80426716 0.82096475 0.84693878 0.84879406 0.80055659 0.81910946\n",
      " 0.84786642 0.84879406 0.80148423 0.81818182 0.84786642 0.84693878\n",
      " 0.79962894 0.81632653 0.84693878 0.84693878 0.79962894 0.81632653\n",
      " 0.84879406 0.84693878 0.79962894 0.81632653 0.84601113 0.84693878\n",
      " 0.79962894 0.81632653 0.84601113 0.85064935 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "RandomForestClassifier: 100%|███████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 22, 'n_estimators': 100}\n",
      "Best training accuracy: 0.853\n",
      "Validation set accuracy score for best params: 0.900\n",
      "\n",
      "Classifier with best validation set accuracy: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RandomForestClassifier'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ModelSelection(grids,grid_dict).choose(X_train,y_train,X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "72 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of SVC must be a str among {'balanced'}, an instance of 'dict' or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.27643785 0.12430427 0.12430427 0.27643785 0.12430427 0.12430427\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.47402597 0.16141002 0.14935065 0.47402597 0.29220779 0.06122449\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59090909 0.20037106 0.16512059 0.59090909 0.42207792 0.06215213\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60760668 0.2096475  0.17532468 0.60760668 0.46474954 0.05565863\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66883117 0.25510204 0.1419295  0.66883117 0.66233766 0.11595547\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67625232 0.28849722 0.12523191 0.67625232 0.75881262 0.09647495\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n",
      "Fitting 2 folds for each of 784 candidates, totalling 1568 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.29962894 0.55565863 0.72820037 0.77458256 0.78571429 0.78571429\n",
      " 0.78571429 0.78571429 0.78571429 0.78571429 0.29962894 0.58534323\n",
      " 0.72541744 0.79499072 0.80705009 0.80705009 0.80705009 0.80705009\n",
      " 0.80705009 0.80705009        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "784 fits failed out of a total of 1568.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "495 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced_subsample', 'balanced'}, an instance of 'dict', an instance of 'list' or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "289 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced', 'balanced_subsample'}, an instance of 'dict', an instance of 'list' or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.29684601 0.40352505 0.46289425 0.45083488 0.35992579 0.40723562\n",
      " 0.51205937 0.49257885 0.4174397  0.49536178 0.5742115  0.56029685\n",
      " 0.51391466 0.55473098 0.62523191 0.61688312 0.50278293 0.60667904\n",
      " 0.68367347 0.68460111 0.62523191 0.67903525 0.72541744 0.73376623\n",
      " 0.67532468 0.73005566 0.74953618 0.76530612 0.68089054 0.74675325\n",
      " 0.79220779 0.78571429 0.73376623 0.76345083 0.81168831 0.81076067\n",
      " 0.72170686 0.7690167  0.81910946 0.81818182 0.75788497 0.78200371\n",
      " 0.81910946 0.82189239 0.75139147 0.79128015 0.82745826 0.82560297\n",
      " 0.783859   0.80890538 0.84044527 0.84137291 0.78849722 0.82374768\n",
      " 0.84137291 0.8432282  0.77272727 0.81168831 0.83766234 0.84044527\n",
      " 0.783859   0.80241187 0.8432282  0.84044527 0.77643785 0.80241187\n",
      " 0.84508349 0.84415584 0.79128015 0.82003711 0.84601113 0.8432282\n",
      " 0.77736549 0.81818182 0.84972171 0.84879406 0.78107607 0.8135436\n",
      " 0.84879406 0.84786642 0.78200371 0.81447124 0.84044527 0.84693878\n",
      " 0.78756957 0.80705009 0.84786642 0.84693878 0.783859   0.81818182\n",
      " 0.84230056 0.84693878 0.79220779 0.82003711 0.84693878 0.84786642\n",
      " 0.783859   0.81725417 0.8432282  0.84693878 0.78942486 0.81725417\n",
      " 0.84786642 0.84879406 0.78942486 0.81725417 0.84693878 0.85064935\n",
      " 0.78942486 0.81725417 0.84415584 0.84879406 0.78942486 0.81725417\n",
      " 0.84601113 0.85064935 0.78942486 0.81725417 0.84415584 0.85064935\n",
      " 0.78942486 0.81725417 0.84415584 0.85064935 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.78942486 0.81725417\n",
      " 0.84508349 0.85157699 0.78942486 0.81725417 0.84508349 0.85157699\n",
      " 0.78942486 0.81725417 0.84508349 0.85157699 0.30983302 0.40630798\n",
      " 0.45361781 0.46382189 0.3877551  0.41558442 0.52504638 0.52226345\n",
      " 0.43320965 0.49350649 0.57699443 0.56400742 0.50834879 0.57142857\n",
      " 0.61317254 0.60018553 0.54823748 0.61595547 0.66604824 0.65769944\n",
      " 0.60760668 0.65955473 0.72541744 0.73005566 0.64471243 0.69758813\n",
      " 0.7541744  0.76808905 0.6567718  0.71335807 0.78014842 0.7755102\n",
      " 0.68738404 0.73654917 0.79499072 0.80612245 0.71985158 0.77458256\n",
      " 0.80426716 0.81261596 0.73376623 0.78664193 0.81261596 0.82560297\n",
      " 0.75046382 0.80333952 0.83209647 0.83395176 0.76623377 0.80055659\n",
      " 0.83209647 0.83116883 0.77179963 0.80890538 0.83302412 0.83766234\n",
      " 0.76808905 0.80148423 0.83858998 0.84044527 0.78942486 0.82003711\n",
      " 0.84786642 0.84693878 0.79406308 0.81261596 0.85064935 0.84786642\n",
      " 0.79777365 0.8135436  0.85064935 0.84415584 0.78107607 0.79962894\n",
      " 0.84137291 0.84415584 0.7987013  0.81076067 0.84693878 0.84879406\n",
      " 0.79777365 0.81261596 0.8432282  0.84415584 0.80241187 0.82189239\n",
      " 0.85250464 0.85343228 0.81261596 0.82003711 0.85250464 0.85064935\n",
      " 0.82189239 0.81910946 0.84786642 0.84693878 0.80612245 0.82003711\n",
      " 0.84879406 0.84693878 0.80148423 0.81539889 0.84693878 0.84693878\n",
      " 0.80426716 0.82096475 0.84693878 0.84879406 0.80055659 0.81910946\n",
      " 0.84786642 0.84879406 0.80148423 0.81818182 0.84786642 0.84693878\n",
      " 0.79962894 0.81632653 0.84693878 0.84693878 0.79962894 0.81632653\n",
      " 0.84879406 0.84693878 0.79962894 0.81632653 0.84601113 0.84693878\n",
      " 0.79962894 0.81632653 0.84601113 0.85064935 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171 0.79962894 0.81632653 0.84601113 0.84972171\n",
      " 0.79962894 0.81632653 0.84601113 0.84972171 0.79962894 0.81632653\n",
      " 0.84601113 0.84972171        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'gamma':...</td>\n",
       "      <td>0.859259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                              param  \\\n",
       "0                     SVC  {'C': 10, 'class_weight': 'balanced', 'gamma':...   \n",
       "1  DecisionTreeClassifier  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "2  RandomForestClassifier  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "\n",
       "   valid_score  \n",
       "0     0.859259  \n",
       "1     0.866667  \n",
       "2     0.900000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSelection(grids,grid_dict).best_results(X_train,y_train,X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finalize()` class\n",
    " - Takes an estimator.\n",
    " - Method `final_score()` takes `X_train`, `y_train`, `X_test`, `y_test` and returns the accuracy of the model as in the example below:\n",
    "```\n",
    "final.final_score(X_train, y_train, X_test, y_test)\n",
    "Accuracy of the final model is 0.908284023668639\n",
    "```\n",
    " - Method `save_model()` takes a path, saves the model to this path and prints that the model was successfully saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accurancy of the final model is 0.908284023668639'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Finalize(object):\n",
    "    def __init__(self,estimators):\n",
    "        self.estinators = estimators\n",
    "    def final_score(self,X_train,y_train,X_test,y_test):\n",
    "        self.estinators.fit(X_train,y_train)\n",
    "        y_pr = self.estinators.predict(X_test)\n",
    "        return f'Accurancy of the final model is {accuracy_score(y_test,y_pr)}'\n",
    "    def save_model(self,path):\n",
    "        joblib.dump(self.estinators,path)\n",
    "        print(\"Модель успешно сохранена\")\n",
    "    \n",
    "Finalize(model_random).final_score(X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно сохранена\n"
     ]
    }
   ],
   "source": [
    "Finalize(model_random).save_model('best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data from the file (****name of file****).\n",
    "2. Create the preprocessing pipeline that consists of two custom transformers: `FeatureExtractor()` and `MyOneHotEncoder()`:\n",
    "```\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "```\n",
    "3. Use that pipeline and its method `fit_transform()` on the initial dataset.\n",
    "```\n",
    "data = preprocessing.fit_transform(df)\n",
    "```\n",
    "4. Get `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` using `TrainValidationTest()` and the result of the pipeline.\n",
    "5. Create an instance of `ModelSelection()`, use the method `choose()` applying it to the models that you want and parameters that you want, get the dataframe of the best results.\n",
    "6. create an instance of `Finalize()` with your best model, use method `final_score()` and save the model in the format: `name_of_the_model_{accuracy on test dataset}.sav`.\n",
    "\n",
    "That is it, congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>labname</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-17 05:19:02.744528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-17 05:22:45.549397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-17 05:34:24.422370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-17 05:43:27.773992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-04-17 05:46:32.275104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>user_19</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-21 20:01:48.959966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-05-21 20:18:54.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-05-21 20:19:06.872761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-05-21 20:22:41.877806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-21 20:37:00.290491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid   labname  numTrials                   timestamp\n",
       "0      user_4  project1          1  2020-04-17 05:19:02.744528\n",
       "1      user_4  project1          2  2020-04-17 05:22:45.549397\n",
       "2      user_4  project1          3  2020-04-17 05:34:24.422370\n",
       "3      user_4  project1          4  2020-04-17 05:43:27.773992\n",
       "4      user_4  project1          5  2020-04-17 05:46:32.275104\n",
       "...       ...       ...        ...                         ...\n",
       "1681  user_19   laba06s          9  2020-05-21 20:01:48.959966\n",
       "1682   user_1   laba06s          6  2020-05-21 20:18:54.487900\n",
       "1683   user_1   laba06s          7  2020-05-21 20:19:06.872761\n",
       "1684   user_1   laba06s          8  2020-05-21 20:22:41.877806\n",
       "1685   user_1   laba06s          9  2020-05-21 20:37:00.290491\n",
       "\n",
       "[1686 rows x 4 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/checker_submits.csv')\n",
    "data['uid'] = data[\"uid\"].astype('category')\n",
    "data['labname'] = data[\"labname\"].astype('category')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FeatureExtractor.__init__() missing 1 required positional argument: 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[153]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m preprocessing_pipeline = Pipeline([\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mfeature_extractor\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[32m      3\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33monehot_encoder\u001b[39m\u001b[33m'\u001b[39m, MyOneHotEncoder(target=\u001b[33m'\u001b[39m\u001b[33mdayofweek\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      4\u001b[39m ])\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Применение предобработки к данным\u001b[39;00m\n\u001b[32m      7\u001b[39m processed_data = preprocessing_pipeline.fit_transform(data)\n",
      "\u001b[31mTypeError\u001b[39m: FeatureExtractor.__init__() missing 1 required positional argument: 'df'"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('feature_extractor', FeatureExtractor()),\n",
    "    ('onehot_encoder', MyOneHotEncoder(target='dayofweek'))\n",
    "])\n",
    "\n",
    "\n",
    "processed_data = preprocessing_pipeline.fit_transform(data)\n",
    "\n",
    "\n",
    "X = processed_data.drop(columns=['dayofweek']) \n",
    "Y = processed_data['dayofweek']\n",
    "\n",
    "train_val_test = TrainValidationTest(X, Y)\n",
    "X_train, X_test, y_train, y_test, X_valid, y_valid = train_val_test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
